{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get list of cited DOIs to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, \"./modules\")\n",
    "import bs_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data'\n",
    "FTP_PUBMED_papers = os.path.join(data_path, 'FTP_PUBMED_papers')\n",
    "\n",
    "DOI_list = [\"10.1126/science.1179052\"]\n",
    "ds_name = 'DOI_cited_science_1179052_retracted'\n",
    "\n",
    "analysis_path = os.path.join(data_path, 'analysis')\n",
    "citing_tsv = os.path.join(analysis_path, '%s.tsv' % ds_name)\n",
    "citing_prep_tsv = os.path.join(analysis_path, '%s_prep.tsv' % ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find papers in FTP_PUBMED citing these DOIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(FTP_PUBMED_papers):\n",
    "    raise RuntimeError('%s does not exist, did you download the data?' % FTP_PUBMED_papers)\n",
    "\n",
    "os.makedirs(analysis_path, exist_ok=True)\n",
    "\n",
    "if os.path.isfile(citing_tsv):\n",
    "    os.remove(citing_tsv)\n",
    "\n",
    "for doi_index, DOI in enumerate(DOI_list):\n",
    "    print(DOI)\n",
    "    DOI_cited_in  = \" \"\n",
    "    for filename in sorted(glob.glob(FTP_PUBMED_papers + '/*')):\n",
    "        if not os.path.isfile(filename):\n",
    "            continue\n",
    "        print('%s' % filename)\n",
    "        command = [\"zgrep\", \"-a\", DOI, filename]\n",
    "        try:\n",
    "            DOI_cited_in_bytes = subprocess.check_output(\n",
    "                command,\n",
    "                stderr=subprocess.STDOUT\n",
    "            )\n",
    "            DOI_cited_in = DOI_cited_in + \" \" + DOI_cited_in_bytes.decode(\"utf-8\") # conver bytes into strings\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            if e.returncode == 1 and not e.output:\n",
    "                # assume it just didn't find anything\n",
    "                pass\n",
    "            else:\n",
    "                print(\"Subprocess output:\", e.output)\n",
    "                raise RuntimeError(\n",
    "                    'non-zero exit status %d for command %s' % (e.returncode, command)\n",
    "                )\n",
    "    \n",
    "    list_articles_citing = []\n",
    "    DOI_cited_in_BS = BeautifulSoup(DOI_cited_in, \"lxml\")\n",
    "    for article in DOI_cited_in_BS.prettify().split('</article>'):\n",
    "        # Not all the articles start or finish with this tag.\n",
    "        article_BS = BeautifulSoup(article, \"lxml\")\n",
    "        # ('<article article-type'): #In some cases the seaparation between 2 articles i<\\ref> <article article-type> \n",
    "        for article2 in article_BS.prettify().split('</back>'):\n",
    "            # To remove spliting of some end-tags\n",
    "            if (DOI in article2) and (len(str(article2)) > 800):\n",
    "                list_articles_citing.append(article2)\n",
    "\n",
    "    if not list_articles_citing:\n",
    "        raise RuntimeError('no articles matching criteria found')\n",
    "\n",
    "    df2 = pd.DataFrame([\n",
    "        [DOI, article_citing]\n",
    "        for article_citing in list_articles_citing\n",
    "    ], columns=['DOI_cited', 'article_citing'])\n",
    "    \n",
    "    df2.to_csv(\n",
    "        citing_tsv,\n",
    "        header=doi_index == 0,\n",
    "        index=False,\n",
    "        mode='w' if doi_index == 0 else 'a',\n",
    "        sep='\\t',\n",
    "        encoding='utf-8'\n",
    "    )\n",
    "    print(\"Data saved to\", citing_tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_citing_tsv = lambda filename: pd.read_csv(\n",
    "    filename,\n",
    "    sep='\\t',\n",
    "    encoding='utf-8'\n",
    ")\n",
    "\n",
    "df_citing = read_citing_tsv(citing_tsv)\n",
    "df_citing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_citing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for DOI in df_citing.DOI_cited.unique():\n",
    "    print(df_citing[df_citing['DOI_cited'] == DOI].shape, '\\t\\t', DOI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepocessing data. Remove random spaces and store in a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file again (for good measure)\n",
    "df_citing = read_citing_tsv(citing_tsv)\n",
    "\n",
    "# preprocess data\n",
    "df_prep = df_citing.copy()\n",
    "df_prep['article_citing'] = df_citing['article_citing'].apply(bs_preprocess.bs_preprocess)    \n",
    "\n",
    "df_prep.to_csv(citing_prep_tsv, index=False, sep='\\t', encoding='utf-8')\n",
    "print(\"wrote to:\", citing_prep_tsv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
